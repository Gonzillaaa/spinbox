# Roadmap: Production Deployment

## Vision

Enable Spinbox projects to be deployed to production environments with minimal friction, targeting simple VPS/Docker setups while maintaining a path to more sophisticated deployments.

---

## Current State Analysis

### What Spinbox Generates (Development Only)

**`.devcontainer/Dockerfile`:**
- Full development environment
- Includes dev tools (git, vim, curl, build tools)
- Large image size (~1-2GB)
- Optimized for developer experience, not production

**`docker-compose.yml`:**
- Bind mounts for live code reloading
- Development credentials (postgres/postgres)
- No health checks
- No restart policies
- Volumes point to local directories

### Why This Isn't Production-Ready

| Aspect | Development | Production Needs |
|--------|-------------|------------------|
| Image size | Large (dev tools) | Small (runtime only) |
| Code | Bind-mounted | Baked into image |
| Secrets | Hardcoded | Environment variables |
| Restart | Manual | Automatic (always) |
| Health | None | Health checks |
| Logging | Console | Centralized |
| SSL | None | Required |

---

## Phase 1: Production Docker Files

### Goal

Generate production-ready Docker configurations alongside development configs.

### New Command

```bash
spinbox build --prod [OPTIONS]

OPTIONS:
    --output DIR          Output directory (default: current directory)
    --no-compose          Skip docker-compose.prod.yml generation
    --target TARGET       Target runtime: python, node, or auto-detect

GENERATES:
    Dockerfile.prod
    docker-compose.prod.yml
    .env.example
    deploy/README.md
```

### Generated Files

#### Dockerfile.prod (FastAPI/Python)

```dockerfile
# =============================================================================
# Production Dockerfile for FastAPI Application
# Generated by Spinbox - customize as needed
# =============================================================================

# -----------------------------------------------------------------------------
# Stage 1: Builder - Install dependencies
# -----------------------------------------------------------------------------
FROM python:3.11-slim AS builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY backend/requirements.txt .
RUN pip install --no-cache-dir --target=/app/dependencies -r requirements.txt

# -----------------------------------------------------------------------------
# Stage 2: Runtime - Minimal production image
# -----------------------------------------------------------------------------
FROM python:3.11-slim AS runtime

# Security: Run as non-root user
RUN useradd --create-home --shell /bin/bash app
USER app

WORKDIR /app

# Copy dependencies from builder
COPY --from=builder /app/dependencies /usr/local/lib/python3.11/site-packages

# Copy application code
COPY --chown=app:app backend/ .

# Environment
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')" || exit 1

# Run application
CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Key production optimizations:**
- Multi-stage build (smaller final image)
- Non-root user for security
- No dev tools included
- Health check endpoint
- Optimized Python settings

#### Dockerfile.prod (Next.js/Node)

```dockerfile
# =============================================================================
# Production Dockerfile for Next.js Application
# Generated by Spinbox - customize as needed
# =============================================================================

# -----------------------------------------------------------------------------
# Stage 1: Dependencies
# -----------------------------------------------------------------------------
FROM node:20-alpine AS deps
WORKDIR /app
COPY frontend/package*.json ./
RUN npm ci --only=production

# -----------------------------------------------------------------------------
# Stage 2: Builder
# -----------------------------------------------------------------------------
FROM node:20-alpine AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY frontend/ .
RUN npm run build

# -----------------------------------------------------------------------------
# Stage 3: Runner
# -----------------------------------------------------------------------------
FROM node:20-alpine AS runner
WORKDIR /app

ENV NODE_ENV=production

# Security: Run as non-root
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs
USER nextjs

# Copy built application
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static
COPY --from=builder --chown=nextjs:nodejs /app/public ./public

EXPOSE 3000
ENV PORT=3000

HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1

CMD ["node", "server.js"]
```

#### docker-compose.prod.yml

```yaml
# =============================================================================
# Production Docker Compose
# Generated by Spinbox - customize as needed
# =============================================================================
#
# Usage:
#   docker compose -f docker-compose.prod.yml up -d
#
# Required environment variables (see .env.example):
#   - DATABASE_URL
#   - POSTGRES_PASSWORD
#   - SECRET_KEY
#   - (add others as needed)
# =============================================================================

version: '3.8'

services:
  # ---------------------------------------------------------------------------
  # Application
  # ---------------------------------------------------------------------------
  app:
    build:
      context: .
      dockerfile: Dockerfile.prod
    restart: always
    ports:
      - "${APP_PORT:-8000}:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # PostgreSQL Database
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    restart: always
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-app}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Note: In production, consider NOT exposing the port
    # and accessing only through the app service
    # ports:
    #   - "5432:5432"

  # ---------------------------------------------------------------------------
  # Redis Cache
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    restart: always
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

# -----------------------------------------------------------------------------
# Volumes - Persistent storage
# -----------------------------------------------------------------------------
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

# -----------------------------------------------------------------------------
# Networks (optional - for multiple services)
# -----------------------------------------------------------------------------
# networks:
#   app_network:
#     driver: bridge
```

#### .env.example

```bash
# =============================================================================
# Production Environment Variables
# Generated by Spinbox
# =============================================================================
# Copy this file to .env and fill in the values
# NEVER commit .env to version control!
# =============================================================================

# -----------------------------------------------------------------------------
# Application
# -----------------------------------------------------------------------------
APP_PORT=8000
SECRET_KEY=generate-a-secure-random-string-here
DEBUG=false

# -----------------------------------------------------------------------------
# Database (PostgreSQL)
# -----------------------------------------------------------------------------
POSTGRES_USER=postgres
POSTGRES_PASSWORD=CHANGE_THIS_TO_A_SECURE_PASSWORD
POSTGRES_DB=myapp

# Connection URL (used by application)
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}

# -----------------------------------------------------------------------------
# Redis
# -----------------------------------------------------------------------------
REDIS_URL=redis://redis:6379

# -----------------------------------------------------------------------------
# Optional: External Services
# -----------------------------------------------------------------------------
# OPENAI_API_KEY=sk-...
# SMTP_HOST=smtp.example.com
# SMTP_USER=...
# SMTP_PASSWORD=...
```

#### deploy/README.md

```markdown
# Deployment Guide

## Prerequisites

- Docker and Docker Compose installed on server
- Domain name (optional, for SSL)
- Server with at least 1GB RAM

## Quick Deploy

1. **Copy files to server:**
   ```bash
   scp -r Dockerfile.prod docker-compose.prod.yml .env.example backend/ user@server:/app/
   ```

2. **Configure environment:**
   ```bash
   ssh user@server
   cd /app
   cp .env.example .env
   # Edit .env with production values
   nano .env
   ```

3. **Start services:**
   ```bash
   docker compose -f docker-compose.prod.yml up -d
   ```

4. **Verify:**
   ```bash
   docker compose -f docker-compose.prod.yml ps
   curl http://localhost:8000/health
   ```

## SSL with Caddy (Recommended)

Add Caddy as reverse proxy for automatic HTTPS:

```yaml
# Add to docker-compose.prod.yml
caddy:
  image: caddy:2-alpine
  restart: always
  ports:
    - "80:80"
    - "443:443"
  volumes:
    - ./Caddyfile:/etc/caddy/Caddyfile
    - caddy_data:/data
```

```
# Caddyfile
yourdomain.com {
    reverse_proxy app:8000
}
```

## Common Operations

```bash
# View logs
docker compose -f docker-compose.prod.yml logs -f app

# Restart application
docker compose -f docker-compose.prod.yml restart app

# Update application
git pull
docker compose -f docker-compose.prod.yml build app
docker compose -f docker-compose.prod.yml up -d app

# Database backup
docker compose -f docker-compose.prod.yml exec postgres pg_dump -U postgres app > backup.sql
```

## Troubleshooting

- **App won't start:** Check logs, verify environment variables
- **Database connection failed:** Ensure postgres is healthy, check DATABASE_URL
- **Out of memory:** Increase server RAM or add swap
```

---

## Phase 2: Deploy Guide Command

### Goal

Provide interactive deployment guidance without actually deploying.

### New Command

```bash
spinbox deploy --target TARGET [OPTIONS]

TARGETS:
    docker          Simple docker-compose on VPS
    docker-swarm    Docker Swarm cluster (future)

OPTIONS:
    --generate      Generate deployment files (calls spinbox build --prod)
    --check         Verify deployment prerequisites
    --guide         Show deployment guide (default)
```

### Example Output

```
$ spinbox deploy --target docker

Production Deployment Guide for: myproject
==========================================

Your project uses: FastAPI, PostgreSQL, Redis

Step 1: Generate Production Files
---------------------------------
Run: spinbox build --prod

This creates:
  - Dockerfile.prod (optimized application image)
  - docker-compose.prod.yml (production services)
  - .env.example (required environment variables)
  - deploy/README.md (detailed guide)

Step 2: Configure Secrets
-------------------------
Required environment variables:
  - POSTGRES_PASSWORD: Database password (generate secure random string)
  - SECRET_KEY: Application secret (generate secure random string)
  - DATABASE_URL: Will be auto-constructed from other vars

Generate secure passwords:
  openssl rand -hex 32

Step 3: Deploy to Server
------------------------
Option A - Copy files manually:
  scp Dockerfile.prod docker-compose.prod.yml backend/ user@server:/app/

Option B - Use Git on server:
  ssh user@server "cd /app && git pull"

Step 4: Start Services
----------------------
ssh user@server "cd /app && docker compose -f docker-compose.prod.yml up -d"

Step 5: Verify
--------------
curl https://your-domain.com/health

Need more help? See: deploy/README.md
```

---

## Phase 3: CI/CD Templates (Future)

### Goal

Generate CI/CD workflows for automated deployment.

### New Command

```bash
spinbox generate --ci PLATFORM [OPTIONS]

PLATFORMS:
    github          GitHub Actions
    gitlab          GitLab CI

OPTIONS:
    --deploy        Include deployment step
    --test          Include test step (default: true)
    --registry      Docker registry for images
```

### Generated GitHub Actions Workflow

```yaml
# .github/workflows/deploy.yml
name: Build and Deploy

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r backend/requirements.txt
          pip install pytest

      - name: Run tests
        run: pytest backend/tests/

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.prod
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Deploy to server
        uses: appleboy/ssh-action@v1
        with:
          host: ${{ secrets.SERVER_HOST }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          script: |
            cd /app
            docker compose -f docker-compose.prod.yml pull
            docker compose -f docker-compose.prod.yml up -d
```

---

## Future Phases (Not Planned Yet)

### Phase 4: Platform-Specific Deployment

Support for managed platforms:

```bash
spinbox deploy --target railway
spinbox deploy --target fly
spinbox deploy --target render
```

Would generate platform-specific configs:
- `railway.json`
- `fly.toml`
- `render.yaml`

### Phase 5: Kubernetes

For teams that need orchestration:

```bash
spinbox deploy --target kubernetes
```

Would generate:
- Deployment manifests
- Service definitions
- ConfigMaps/Secrets
- Ingress configuration

**Note:** This is significant complexity and should only be considered if there's clear demand.

---

## Design Principles

1. **Generate, don't deploy** - Spinbox creates files, user deploys them
2. **Visible, not magic** - Generated files are readable and documented
3. **Secure defaults** - Non-root users, no hardcoded secrets, health checks
4. **Progressive complexity** - Start simple (VPS), grow as needed
5. **Platform agnostic** - Standard Docker, works anywhere

---

## Security Considerations

### What Spinbox Does

- Generates `.env.example` (never `.env` with real values)
- Uses non-root users in Dockerfiles
- Adds health checks for reliability
- Documents security best practices

### What Users Must Do

- Generate strong passwords
- Never commit `.env` files
- Set up SSL/TLS (we suggest Caddy)
- Configure firewalls
- Set up backups
- Monitor logs

---

## Alternative Approaches Considered

### 1. Direct Deployment (Rejected)

**Idea:** `spinbox deploy` actually deploys to server
**Why rejected:**
- Requires storing server credentials
- Too much can go wrong
- Users should understand deployment

### 2. Managed Service Integration (Deferred)

**Idea:** Deep integration with Railway, Fly.io, etc.
**Why deferred:**
- Each platform has different APIs
- Maintenance burden
- Platforms change frequently

### 3. Kubernetes-First (Rejected)

**Idea:** Generate Kubernetes manifests by default
**Why rejected:**
- Overkill for most Spinbox users
- Significant complexity
- docker-compose covers 90% of use cases

---

## Success Metrics

- Time from "code complete" to "running in production"
- Number of deployment-related support questions
- User feedback on generated file quality

---

## Open Questions

1. Should we generate Nginx configs as alternative to Caddy?
2. How to handle database migrations in deployment?
3. Should we support multiple environments (staging, prod)?
4. Generate monitoring configs (Prometheus, etc.)?

---

## Related Documentation

- [Architecture](./architecture.md) - Overall system design
- [Sharing Roadmap](./roadmap-sharing.md) - Team collaboration features
