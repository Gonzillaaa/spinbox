#!/bin/bash
# PostgreSQL component generator for Spinbox
# Creates PostgreSQL database with PGVector extension and initialization scripts

# Source required libraries
source "$(dirname "${BASH_SOURCE[0]}")/../lib/utils.sh"
source "$(dirname "${BASH_SOURCE[0]}")/../lib/config.sh"
source "$(dirname "${BASH_SOURCE[0]}")/../lib/version-config.sh"

# Generate PostgreSQL database component
function generate_postgresql_component() {
    local project_dir="$1"
    local postgresql_dir="$project_dir/postgresql"
    
    if [[ "$DRY_RUN" == true ]]; then
        print_info "DRY RUN: Would generate PostgreSQL database component"
        return 0
    fi
    
    print_status "Creating PostgreSQL database component..."
    
    # Ensure database directory exists
    safe_create_dir "$postgresql_dir"
    safe_create_dir "$postgresql_dir/init"
    safe_create_dir "$postgresql_dir/scripts"
    safe_create_dir "$postgresql_dir/migrations"
    
    # Generate database files
    generate_postgresql_init_scripts "$postgresql_dir"
    generate_postgresql_config "$postgresql_dir"
    generate_postgresql_scripts "$postgresql_dir"
    generate_postgresql_env_files "$postgresql_dir"
    
    # Generate working examples if requested
    if [[ "${WITH_EXAMPLES:-false}" == "true" ]]; then
        generate_postgresql_working_examples "$postgresql_dir"
    fi
    
    print_status "PostgreSQL database component created successfully"
}

# Generate database initialization scripts
function generate_postgresql_init_scripts() {
    local postgresql_dir="$1"
    local init_dir="$postgresql_dir/init"
    
    # Main initialization script
    cat > "$init_dir/01-init.sql" << EOF
-- Database initialization for ${PROJECT_NAME:-app}
-- Generated by Spinbox on $(date)

-- Create database if it doesn't exist (PostgreSQL will create it automatically)
-- \\c ${PROJECT_NAME:-app};

-- Enable required extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";

-- Enable PGVector extension for vector operations
CREATE EXTENSION IF NOT EXISTS vector;

-- Create basic tables
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    email VARCHAR(255) UNIQUE NOT NULL,
    username VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(255),
    is_active BOOLEAN DEFAULT true,
    is_superuser BOOLEAN DEFAULT false,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Create items table (example)
CREATE TABLE IF NOT EXISTS items (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    owner_id UUID REFERENCES users(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Create vector embeddings table (if using AI/ML features)
CREATE TABLE IF NOT EXISTS embeddings (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    content TEXT NOT NULL,
    embedding vector(1536), -- OpenAI embedding dimension
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for performance
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_users_username ON users(username);
CREATE INDEX IF NOT EXISTS idx_items_owner_id ON items(owner_id);
CREATE INDEX IF NOT EXISTS idx_items_created_at ON items(created_at);

-- Vector similarity index (for embeddings)
CREATE INDEX IF NOT EXISTS idx_embeddings_cosine 
ON embeddings USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);

-- Update timestamp trigger function
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS \$\$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
\$\$ language 'plpgsql';

-- Add update triggers
CREATE TRIGGER update_users_updated_at 
    BEFORE UPDATE ON users 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_items_updated_at 
    BEFORE UPDATE ON items 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

-- Create basic functions
CREATE OR REPLACE FUNCTION search_similar_embeddings(
    query_embedding vector(1536),
    match_threshold float DEFAULT 0.8,
    match_count int DEFAULT 10
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    similarity FLOAT,
    metadata JSONB
) 
LANGUAGE SQL STABLE
AS \$\$
SELECT
    embeddings.id,
    embeddings.content,
    1 - (embeddings.embedding <=> query_embedding) AS similarity,
    embeddings.metadata
FROM embeddings
WHERE 1 - (embeddings.embedding <=> query_embedding) > match_threshold
ORDER BY embeddings.embedding <=> query_embedding
LIMIT match_count;
\$\$;

-- Insert sample data
INSERT INTO users (email, username, full_name, is_superuser) 
VALUES ('admin@example.com', 'admin', 'System Administrator', true)
ON CONFLICT (email) DO NOTHING;

INSERT INTO items (title, description, owner_id)
SELECT 
    'Sample Item',
    'This is a sample item created during database initialization',
    u.id
FROM users u 
WHERE u.username = 'admin'
ON CONFLICT DO NOTHING;
EOF

    # Vector database specific initialization
    cat > "$init_dir/02-vector-setup.sql" << 'EOF'
-- Vector database specific setup
-- This script sets up additional vector database functionality

-- Create collections table for organizing embeddings
CREATE TABLE IF NOT EXISTS collections (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    name VARCHAR(255) UNIQUE NOT NULL,
    description TEXT,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Update embeddings table to reference collections
ALTER TABLE embeddings 
ADD COLUMN IF NOT EXISTS collection_id UUID REFERENCES collections(id) ON DELETE CASCADE;

-- Create index on collection_id
CREATE INDEX IF NOT EXISTS idx_embeddings_collection_id ON embeddings(collection_id);

-- Create default collection
INSERT INTO collections (name, description)
VALUES ('default', 'Default collection for embeddings')
ON CONFLICT (name) DO NOTHING;

-- Function to add embedding with automatic collection assignment
CREATE OR REPLACE FUNCTION add_embedding(
    p_content TEXT,
    p_embedding vector(1536),
    p_metadata JSONB DEFAULT '{}',
    p_collection_name VARCHAR(255) DEFAULT 'default'
)
RETURNS UUID
LANGUAGE PLPGSQL
AS $$
DECLARE
    collection_uuid UUID;
    embedding_uuid UUID;
BEGIN
    -- Get or create collection
    SELECT id INTO collection_uuid
    FROM collections
    WHERE name = p_collection_name;
    
    IF collection_uuid IS NULL THEN
        INSERT INTO collections (name)
        VALUES (p_collection_name)
        RETURNING id INTO collection_uuid;
    END IF;
    
    -- Insert embedding
    INSERT INTO embeddings (content, embedding, metadata, collection_id)
    VALUES (p_content, p_embedding, p_metadata, collection_uuid)
    RETURNING id INTO embedding_uuid;
    
    RETURN embedding_uuid;
END;
$$;
EOF

    # Performance and maintenance scripts
    cat > "$init_dir/03-performance.sql" << 'EOF'
-- Performance optimization and maintenance setup

-- Enable query timing
SET track_activity_query_size = 1024;
SET log_min_duration_statement = 1000; -- Log queries taking > 1 second

-- Create performance monitoring view
CREATE OR REPLACE VIEW slow_queries AS
SELECT
    query,
    calls,
    total_time,
    mean_time,
    min_time,
    max_time,
    stddev_time
FROM pg_stat_statements
WHERE mean_time > 100 -- queries with mean time > 100ms
ORDER BY mean_time DESC;

-- Create database statistics function
CREATE OR REPLACE FUNCTION db_stats()
RETURNS TABLE (
    table_name TEXT,
    row_count BIGINT,
    total_size TEXT,
    index_size TEXT,
    toast_size TEXT
)
LANGUAGE PLPGSQL
AS $$
BEGIN
    RETURN QUERY
    SELECT
        schemaname||'.'||tablename AS table_name,
        n_tup_ins - n_tup_del AS row_count,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
        pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) AS index_size,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) AS toast_size
    FROM pg_stat_user_tables
    ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
END;
$$;

-- Create maintenance procedures
CREATE OR REPLACE FUNCTION vacuum_analyze_all()
RETURNS VOID
LANGUAGE PLPGSQL
AS $$
DECLARE
    table_record RECORD;
BEGIN
    FOR table_record IN
        SELECT schemaname, tablename
        FROM pg_tables
        WHERE schemaname = 'public'
    LOOP
        EXECUTE 'VACUUM ANALYZE ' || quote_ident(table_record.schemaname) || '.' || quote_ident(table_record.tablename);
    END LOOP;
END;
$$;
EOF

    print_debug "Generated database initialization scripts"
}

# Generate database configuration files
function generate_postgresql_config() {
    local postgresql_dir="$1"
    
    # PostgreSQL configuration
    cat > "$postgresql_dir/postgresql.conf" << 'EOF'
# PostgreSQL configuration for development
# This file contains optimizations for development workloads

# Connection settings
max_connections = 100
shared_buffers = 128MB
effective_cache_size = 512MB
work_mem = 4MB
maintenance_work_mem = 64MB

# WAL settings
wal_buffers = 16MB
checkpoint_completion_target = 0.9
wal_writer_delay = 200ms

# Query planning
random_page_cost = 1.1
effective_io_concurrency = 200

# Logging
log_destination = 'stderr'
logging_collector = on
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_rotation_size = 10MB
log_min_messages = warning
log_min_error_statement = error
log_min_duration_statement = 1000
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
log_temp_files = 0

# Performance monitoring
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all
EOF

    # Database backup script
    cat > "$postgresql_dir/scripts/backup.sh" << 'EOF'
#!/bin/bash
# Database backup script

set -e

# Configuration
DB_NAME="${POSTGRES_DB:-app}"
DB_USER="${POSTGRES_USER:-postgres}"
DB_HOST="${POSTGRES_HOST:-localhost}"
DB_PORT="${POSTGRES_PORT:-5432}"
BACKUP_DIR="./backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Create backup directory
mkdir -p "$BACKUP_DIR"

# Create backup
echo "Creating backup of database $DB_NAME..."
pg_dump -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" \
    --no-password --verbose --clean --if-exists --format=custom \
    --file="$BACKUP_DIR/${DB_NAME}_${TIMESTAMP}.backup"

echo "Backup completed: $BACKUP_DIR/${DB_NAME}_${TIMESTAMP}.backup"

# Keep only last 7 backups
find "$BACKUP_DIR" -name "${DB_NAME}_*.backup" -type f -mtime +7 -delete

echo "Old backups cleaned up"
EOF

    chmod +x "$postgresql_dir/scripts/backup.sh"

    # Database restore script
    cat > "$postgresql_dir/scripts/restore.sh" << 'EOF'
#!/bin/bash
# Database restore script

set -e

if [ $# -eq 0 ]; then
    echo "Usage: $0 <backup_file>"
    echo "Example: $0 ./backups/app_20231210_143022.backup"
    exit 1
fi

BACKUP_FILE="$1"
DB_NAME="${POSTGRES_DB:-app}"
DB_USER="${POSTGRES_USER:-postgres}"
DB_HOST="${POSTGRES_HOST:-localhost}"
DB_PORT="${POSTGRES_PORT:-5432}"

if [ ! -f "$BACKUP_FILE" ]; then
    echo "Error: Backup file $BACKUP_FILE not found"
    exit 1
fi

echo "Restoring database $DB_NAME from $BACKUP_FILE..."
pg_restore -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" \
    --no-password --verbose --clean --if-exists "$BACKUP_FILE"

echo "Database restored successfully"
EOF

    chmod +x "$postgresql_dir/scripts/restore.sh"

    print_debug "Generated database configuration"
}

# Generate utility scripts
function generate_postgresql_scripts() {
    local postgresql_dir="$1"
    local scripts_dir="$postgresql_dir/scripts"
    
    # Database connection script
    cat > "$scripts_dir/connect.sh" << 'EOF'
#!/bin/bash
# Connect to the database with psql

DB_NAME="${POSTGRES_DB:-app}"
DB_USER="${POSTGRES_USER:-postgres}"
DB_HOST="${POSTGRES_HOST:-localhost}"
DB_PORT="${POSTGRES_PORT:-5432}"

echo "Connecting to database $DB_NAME..."
psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME"
EOF

    chmod +x "$scripts_dir/connect.sh"

    # Database setup script
    cat > "$scripts_dir/setup.sh" << 'EOF'
#!/bin/bash
# Set up database from scratch

set -e

DB_NAME="${POSTGRES_DB:-app}"
DB_USER="${POSTGRES_USER:-postgres}"
DB_HOST="${POSTGRES_HOST:-localhost}"
DB_PORT="${POSTGRES_PORT:-5432}"

echo "Setting up database $DB_NAME..."

# Wait for PostgreSQL to be ready
echo "Waiting for PostgreSQL to be ready..."
until pg_isready -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER"; do
    sleep 1
done

# Run initialization scripts
echo "Running initialization scripts..."
for script in ../init/*.sql; do
    if [ -f "$script" ]; then
        echo "Executing $script..."
        psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -f "$script"
    fi
done

echo "Database setup completed successfully"
EOF

    chmod +x "$scripts_dir/setup.sh"

    # Migration script template
    cat > "$scripts_dir/migrate.sh" << 'EOF'
#!/bin/bash
# Database migration script

set -e

DB_NAME="${POSTGRES_DB:-app}"
DB_USER="${POSTGRES_USER:-postgres}"
DB_HOST="${POSTGRES_HOST:-localhost}"
DB_PORT="${POSTGRES_PORT:-5432}"
MIGRATIONS_DIR="../migrations"

echo "Running database migrations..."

# Create migrations table if it doesn't exist
psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "
CREATE TABLE IF NOT EXISTS schema_migrations (
    version VARCHAR(255) PRIMARY KEY,
    applied_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);"

# Run pending migrations
for migration in "$MIGRATIONS_DIR"/*.sql; do
    if [ -f "$migration" ]; then
        version=$(basename "$migration" .sql)
        
        # Check if migration already applied
        if ! psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -t -c "
            SELECT 1 FROM schema_migrations WHERE version = '$version';" | grep -q 1; then
            
            echo "Applying migration: $version"
            psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -f "$migration"
            
            # Mark as applied
            psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "
                INSERT INTO schema_migrations (version) VALUES ('$version');"
        else
            echo "Migration $version already applied, skipping"
        fi
    fi
done

echo "Migrations completed"
EOF

    chmod +x "$scripts_dir/migrate.sh"

    print_debug "Generated database utility scripts"
}

# Generate environment files
function generate_postgresql_env_files() {
    local postgresql_dir="$1"
    
    # Use security template for .env.example
    local template_file="$PROJECT_ROOT/templates/security/postgresql.env.example"
    if [[ -f "$template_file" ]]; then
        cp "$template_file" "$postgresql_dir/.env.example"
    else
        # Fallback to basic template
        cat > "$postgresql_dir/.env.example" << 'EOF'
# PostgreSQL Database Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=app
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# Connection settings
POSTGRES_MAX_CONNECTIONS=100
POSTGRES_SHARED_BUFFERS=128MB

# Backup settings
BACKUP_RETENTION_DAYS=7
BACKUP_SCHEDULE="0 2 * * *"  # Daily at 2 AM
EOF
    fi

    # Create actual .env if it doesn't exist
    if [[ ! -f "$postgresql_dir/.env" ]]; then
        cp "$postgresql_dir/.env.example" "$postgresql_dir/.env"
    fi

    # Sample migration
    cat > "$postgresql_dir/migrations/001_initial_schema.sql" << 'EOF'
-- Initial schema migration
-- This is an example migration file

-- Add new columns or tables here
-- ALTER TABLE users ADD COLUMN phone VARCHAR(20);

-- Example: Add new table
-- CREATE TABLE user_profiles (
--     id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
--     user_id UUID REFERENCES users(id) ON DELETE CASCADE,
--     bio TEXT,
--     avatar_url VARCHAR(255),
--     created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
-- );
EOF

    print_debug "Generated environment files and sample migration"
}

# Main function to create database component
function create_postgresql_component() {
    local project_dir="$1"
    
    print_info "Creating PostgreSQL database component in $project_dir"
    
    generate_postgresql_component "$project_dir"
    
    print_status "PostgreSQL database component created successfully!"
    print_info "Next steps:"
    echo "  1. cd $(basename "$project_dir")/database"
    echo "  2. Configure environment: cp .env.example .env"
    echo "  3. Start PostgreSQL: docker-compose up -d postgres"
    echo "  4. Run setup: ./scripts/setup.sh"
    echo "  5. Connect: ./scripts/connect.sh"
}

# Generate working examples for PostgreSQL
function generate_postgresql_working_examples() {
    local postgresql_dir="$1"
    local examples_source="$PROJECT_ROOT/templates/examples/core-components/postgresql"
    
    print_info "Adding PostgreSQL working examples..."
    
    # Copy core PostgreSQL examples
    if [[ -d "$examples_source" ]]; then
        # Copy example files
        for example_file in "$examples_source"/example-*.sql; do
            if [[ -f "$example_file" ]]; then
                cp "$example_file" "$postgresql_dir/scripts/"
                print_debug "Copied $(basename "$example_file")"
            fi
        done
        
        # Copy examples README
        if [[ -f "$examples_source/README.md" ]]; then
            cp "$examples_source/README.md" "$postgresql_dir/EXAMPLES.md"
            print_debug "Copied examples documentation"
        fi
        
        print_info "PostgreSQL working examples added successfully"
        print_info "Examples available:"
        echo "  • example-schema.sql - Database schema examples"
        echo "  • example-queries.sql - Common SQL queries"
        echo "  • example-migrations.sql - Migration examples"
        echo "  • EXAMPLES.md - Setup and usage instructions"
    else
        print_warning "PostgreSQL examples directory not found: $examples_source"
    fi
}

# Export functions for use by project generator
export -f generate_postgresql_component create_postgresql_component generate_postgresql_working_examples
export -f generate_postgresql_init_scripts generate_postgresql_config
export -f generate_postgresql_scripts generate_postgresql_env_files