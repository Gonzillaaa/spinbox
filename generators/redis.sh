#!/bin/bash
# Redis component generator for Spinbox
# Creates Redis caching and queue service with Docker setup

# Source required libraries
source "$(dirname "${BASH_SOURCE[0]}")/../lib/utils.sh"
source "$(dirname "${BASH_SOURCE[0]}")/../lib/config.sh"
source "$(dirname "${BASH_SOURCE[0]}")/../lib/version-config.sh"

# Generate Redis caching component
function generate_redis_component() {
    local project_dir="$1"
    local redis_dir="$project_dir/redis"
    
    if [[ "$DRY_RUN" == true ]]; then
        print_info "DRY RUN: Would generate Redis caching component"
        return 0
    fi
    
    print_status "Creating Redis caching component..."
    
    # Ensure redis directory exists
    safe_create_dir "$redis_dir"
    safe_create_dir "$redis_dir/config"
    safe_create_dir "$redis_dir/scripts"
    safe_create_dir "$redis_dir/data"
    
    # Generate redis files
    generate_redis_config "$redis_dir"
    generate_redis_scripts "$redis_dir"
    generate_redis_env_files "$redis_dir"
    
    # Generate working examples if requested
    if [[ "${WITH_EXAMPLES:-false}" == "true" ]]; then
        generate_redis_working_examples "$redis_dir"
    fi
    
    print_status "Redis caching component created successfully"
}

# Generate Redis configuration
function generate_redis_config() {
    local redis_dir="$1"
    local redis_version=$(get_effective_redis_version)
    
    # Redis configuration file
    cat > "$redis_dir/config/redis.conf" << EOF
# Redis configuration for ${PROJECT_NAME:-app}
# Generated by Spinbox on $(date)

# Network
bind 0.0.0.0
port 6379
protected-mode no

# General
daemonize no
supervised no
pidfile /var/run/redis_6379.pid

# Logging
loglevel notice
logfile ""

# Persistence
save 900 1
save 300 10
save 60 10000

stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
dir /data

# Security
# requirepass development_password

# Memory management
maxmemory 256mb
maxmemory-policy allkeys-lru

# Append only file
appendonly yes
appendfilename "appendonly.aof"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# Advanced
timeout 0
tcp-keepalive 300
tcp-backlog 511

# Slow log
slowlog-log-slower-than 10000
slowlog-max-len 128

# Client output buffer limits
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
EOF

    # Docker Compose service definition
    cat > "$redis_dir/docker-compose.yml" << EOF
# Redis service for ${PROJECT_NAME:-app}
# Generated by Spinbox on $(date)

version: '3.8'

services:
  redis:
    image: redis:${redis_version}
    container_name: ${PROJECT_NAME:-app}_redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

volumes:
  redis_data:
    driver: local

networks:
  app_network:
    driver: bridge
EOF

    # Redis Sentinel configuration (for high availability)
    cat > "$redis_dir/config/sentinel.conf" << EOF
# Redis Sentinel configuration for ${PROJECT_NAME:-app}
# Generated by Spinbox on $(date)

# Basic
port 26379
sentinel announce-ip 127.0.0.1
sentinel announce-port 26379

# Monitor master
sentinel monitor mymaster redis 6379 1
sentinel down-after-milliseconds mymaster 30000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 180000

# Security
# sentinel auth-pass mymaster development_password

# Logging
logfile ""
EOF
}

# Generate utility scripts
function generate_redis_scripts() {
    local redis_dir="$1"
    local scripts_dir="$redis_dir/scripts"
    
    # Redis CLI connection script
    cat > "$scripts_dir/cli.sh" << 'EOF'
#!/bin/bash
# Redis CLI access script

REDIS_HOST=${1:-localhost}
REDIS_PORT=${2:-6379}

echo "Connecting to Redis: $REDIS_HOST:$REDIS_PORT"
docker exec -it ${PROJECT_NAME:-app}_redis redis-cli -h "$REDIS_HOST" -p "$REDIS_PORT"
EOF

    # Redis monitoring script
    cat > "$scripts_dir/monitor.sh" << 'EOF'
#!/bin/bash
# Redis monitoring script

echo "Redis Server Status:"
docker exec ${PROJECT_NAME:-app}_redis redis-cli info server

echo -e "\nRedis Memory Usage:"
docker exec ${PROJECT_NAME:-app}_redis redis-cli info memory

echo -e "\nRedis Statistics:"
docker exec ${PROJECT_NAME:-app}_redis redis-cli info stats

echo -e "\nRedis Keyspace:"
docker exec ${PROJECT_NAME:-app}_redis redis-cli info keyspace

echo -e "\nRedis Connected Clients:"
docker exec ${PROJECT_NAME:-app}_redis redis-cli info clients
EOF

    # Cache flush script
    cat > "$scripts_dir/flush.sh" << 'EOF'
#!/bin/bash
# Redis cache flush script

DATABASE=${1:-0}

echo "Flushing Redis database: $DATABASE"
if [[ "$DATABASE" == "all" ]]; then
    docker exec ${PROJECT_NAME:-app}_redis redis-cli flushall
    echo "All databases flushed"
else
    docker exec ${PROJECT_NAME:-app}_redis redis-cli -n "$DATABASE" flushdb
    echo "Database $DATABASE flushed"
fi
EOF

    # Performance test script
    cat > "$scripts_dir/benchmark.sh" << 'EOF'
#!/bin/bash
# Redis performance benchmark

REQUESTS=${1:-10000}
CLIENTS=${2:-50}

echo "Running Redis benchmark:"
echo "Requests: $REQUESTS"
echo "Concurrent clients: $CLIENTS"

docker exec ${PROJECT_NAME:-app}_redis redis-benchmark -n "$REQUESTS" -c "$CLIENTS"
EOF

    # Backup script
    cat > "$scripts_dir/backup.sh" << 'EOF'
#!/bin/bash
# Redis backup script

BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"

echo "Creating backup directory: $BACKUP_DIR"
mkdir -p "$BACKUP_DIR"

echo "Creating Redis backup..."
docker exec ${PROJECT_NAME:-app}_redis redis-cli bgsave
sleep 2

echo "Copying backup files..."
docker cp ${PROJECT_NAME:-app}_redis:/data/dump.rdb "$BACKUP_DIR/"
docker cp ${PROJECT_NAME:-app}_redis:/data/appendonly.aof "$BACKUP_DIR/" 2>/dev/null || true

echo "Backup completed: $BACKUP_DIR"
EOF

    # Make scripts executable
    chmod +x "$scripts_dir"/*.sh
}

# Generate environment files
function generate_redis_env_files() {
    local redis_dir="$1"
    
    # Environment variables for application
    cat > "$redis_dir/.env.redis" << EOF
# Redis environment variables
# Generated by Spinbox on $(date)

# Connection
REDIS_URL=redis://localhost:6379/0
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Connection pool settings
REDIS_MAX_CONNECTIONS=20
REDIS_RETRY_ON_TIMEOUT=true
REDIS_HEALTH_CHECK_INTERVAL=30

# Cache settings
REDIS_DEFAULT_TTL=3600
REDIS_KEY_PREFIX=${PROJECT_NAME:-app}:

# Session settings (if using for sessions)
REDIS_SESSION_DB=1
REDIS_SESSION_TTL=86400

# Queue settings (if using for task queues)
REDIS_QUEUE_DB=2
REDIS_QUEUE_DEFAULT_TIMEOUT=300
EOF

    # FastAPI integration example
    cat > "$redis_dir/fastapi_integration.py" << EOF
# Redis integration for FastAPI
# Generated by Spinbox on $(date)

import redis.asyncio as redis
import os
import json
from typing import Any, Optional, Union
from datetime import timedelta

# Connection configuration
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
REDIS_MAX_CONNECTIONS = int(os.getenv("REDIS_MAX_CONNECTIONS", "20"))
DEFAULT_TTL = int(os.getenv("REDIS_DEFAULT_TTL", "3600"))
KEY_PREFIX = os.getenv("REDIS_KEY_PREFIX", "${PROJECT_NAME:-app}:")

class RedisClient:
    def __init__(self):
        self.redis: Optional[redis.Redis] = None
    
    async def connect(self):
        """Connect to Redis"""
        self.redis = redis.from_url(
            REDIS_URL,
            max_connections=REDIS_MAX_CONNECTIONS,
            decode_responses=True
        )
        await self.redis.ping()
        print("Connected to Redis")
    
    async def disconnect(self):
        """Disconnect from Redis"""
        if self.redis:
            await self.redis.close()
            print("Disconnected from Redis")
    
    def _make_key(self, key: str) -> str:
        """Add prefix to key"""
        return f"{KEY_PREFIX}{key}"
    
    async def get(self, key: str) -> Optional[str]:
        """Get value by key"""
        if not self.redis:
            return None
        return await self.redis.get(self._make_key(key))
    
    async def set(self, key: str, value: str, ttl: Optional[int] = None) -> bool:
        """Set value with optional TTL"""
        if not self.redis:
            return False
        ttl = ttl or DEFAULT_TTL
        return await self.redis.setex(self._make_key(key), ttl, value)
    
    async def delete(self, key: str) -> bool:
        """Delete key"""
        if not self.redis:
            return False
        result = await self.redis.delete(self._make_key(key))
        return result > 0
    
    async def exists(self, key: str) -> bool:
        """Check if key exists"""
        if not self.redis:
            return False
        result = await self.redis.exists(self._make_key(key))
        return result > 0
    
    async def expire(self, key: str, ttl: int) -> bool:
        """Set TTL for existing key"""
        if not self.redis:
            return False
        return await self.redis.expire(self._make_key(key), ttl)
    
    async def get_json(self, key: str) -> Optional[dict]:
        """Get JSON value"""
        value = await self.get(key)
        if value:
            try:
                return json.loads(value)
            except json.JSONDecodeError:
                return None
        return None
    
    async def set_json(self, key: str, value: dict, ttl: Optional[int] = None) -> bool:
        """Set JSON value"""
        try:
            json_str = json.dumps(value)
            return await self.set(key, json_str, ttl)
        except (TypeError, ValueError):
            return False

# Global Redis client instance
redis_client = RedisClient()

async def get_redis() -> RedisClient:
    """Dependency for FastAPI"""
    return redis_client

# Example usage in FastAPI:
#
# from fastapi import FastAPI, Depends
# from .redis_config import redis_client, get_redis
#
# app = FastAPI()
#
# @app.on_event("startup")
# async def startup_redis():
#     await redis_client.connect()
#
# @app.on_event("shutdown")
# async def shutdown_redis():
#     await redis_client.disconnect()
#
# @app.get("/cache/{key}")
# async def get_cache(key: str, redis: RedisClient = Depends(get_redis)):
#     value = await redis.get(key)
#     return {"key": key, "value": value}
EOF

    # Requirements for Redis integration
    cat > "$redis_dir/requirements.txt" << EOF
# Redis dependencies for Python
# Generated by Spinbox on $(date)

redis[hiredis]>=5.0.0     # Async Redis client with C parser
hiredis>=2.2.0            # Fast Redis protocol parser
aioredis>=2.0.0           # Alternative async Redis client
EOF

    # Cache decorator example
    cat > "$redis_dir/cache_decorator.py" << EOF
# Redis cache decorator for FastAPI
# Generated by Spinbox on $(date)

import functools
import json
import hashlib
from typing import Any, Callable, Optional
from .fastapi_integration import redis_client

def cache(ttl: int = 3600, key_prefix: str = "cache"):
    """
    Cache decorator for FastAPI endpoints
    
    Args:
        ttl: Time to live in seconds
        key_prefix: Prefix for cache keys
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        async def wrapper(*args, **kwargs) -> Any:
            # Generate cache key from function name and arguments
            key_data = f"{func.__name__}:{str(args)}:{str(sorted(kwargs.items()))}"
            cache_key = f"{key_prefix}:{hashlib.md5(key_data.encode()).hexdigest()}"
            
            # Try to get from cache
            cached_result = await redis_client.get_json(cache_key)
            if cached_result is not None:
                return cached_result
            
            # Execute function and cache result
            result = await func(*args, **kwargs)
            await redis_client.set_json(cache_key, result, ttl)
            
            return result
        return wrapper
    return decorator

# Example usage:
# @cache(ttl=300, key_prefix="api_data")
# async def get_expensive_data(param: str):
#     # Expensive operation here
#     return {"data": f"result for {param}"}
EOF
}

# Main execution function
function main() {
    local project_dir="${1:-.}"
    
    # Validate project directory
    if [[ ! -d "$project_dir" ]]; then
        print_error "Project directory does not exist: $project_dir"
        return 1
    fi
    
    # Generate Redis component
    generate_redis_component "$project_dir"
    
    return 0
}

# Generate working examples for Redis
function generate_redis_working_examples() {
    local redis_dir="$1"
    local examples_source="$PROJECT_ROOT/templates/examples/core-components/redis"
    
    print_info "Adding Redis working examples..."
    
    # Copy core Redis examples
    if [[ -d "$examples_source" ]]; then
        # Copy example files
        for example_file in "$examples_source"/example-*.py; do
            if [[ -f "$example_file" ]]; then
                cp "$example_file" "$redis_dir/scripts/"
                print_debug "Copied $(basename "$example_file")"
            fi
        done
        
        # Copy examples README
        if [[ -f "$examples_source/README.md" ]]; then
            cp "$examples_source/README.md" "$redis_dir/EXAMPLES.md"
            print_debug "Copied examples documentation"
        fi
        
        print_info "Redis working examples added successfully"
        print_info "Examples available:"
        echo "  • example-caching.py - Caching patterns and strategies"
        echo "  • example-queues.py - Queue/task management"
        echo "  • example-pub-sub.py - Publish/subscribe messaging"
        echo "  • EXAMPLES.md - Setup and usage instructions"
    else
        print_warning "Redis examples directory not found: $examples_source"
    fi
}

# Execute main function if script is run directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi